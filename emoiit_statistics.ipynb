{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"Datasets/EMO-IIT_Separate_Speakers_v2\"\n",
    "SPECTROGRAM_DIR = \"Spectrograms/EMO-IIT_Separate_Speakers_v3/Log\"\n",
    "TF_RECORDS_DIR = \"TFRecords/EMO-IIT_Separate_Speakers_v3_MobileNetV3Large\"\n",
    "TF_RECORDS_NAME = \"EMO-IIT_Separate_Speakers_v3_log_MobileNetV3Large.tfrecords\"\n",
    "MODEL_DIR = \"Models\"\n",
    "MODEL_NAME = \"EMO-IIT_Separate_Speakers_v3_log_MobileNetV3Large.h5\"\n",
    "NUM_CLASSES = 8\n",
    "SAMPLE_RATE = 16000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_emoiit():\n",
    "    if DATASET_DIR != \"Datasets/EMO-IIT\" and DATASET_DIR != \"Datasets/Converted Datasets/EMO-IIT\":\n",
    "        raise Exception(\"DATASET_DIR must be set to 'Datasets/EMO-IIT' or 'Datasets/Converted Datasets/EMO-IIT' for EMO-IIT dataset\")\n",
    "    file_emotion, file_path = [], []\n",
    "    emotion_dir_list = os.listdir(DATASET_DIR)\n",
    "    emotion_dir_list = [emotion_dir for emotion_dir in emotion_dir_list if emotion_dir != \"irritation\"]\n",
    "    for emotion_dir in emotion_dir_list:\n",
    "        file_list = os.listdir(os.path.join(DATASET_DIR, emotion_dir))\n",
    "        for file in file_list:\n",
    "            if file.endswith('.wav'):\n",
    "                file_emotion.append(emotion_dir)\n",
    "                file_path.append(os.path.join(DATASET_DIR, emotion_dir, file))\n",
    "    file_dict = {'emotion': file_emotion, 'path': file_path}\n",
    "    emoiit_df = pd.DataFrame(file_dict)\n",
    "    emoiit_df = pd.DataFrame(shuffle(emoiit_df, random_state=RANDOM_SEED), columns=emoiit_df.columns).reset_index(drop=True, inplace=False)\n",
    "    return emoiit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_emoiit_gendered(irritation=True):\n",
    "    genders = [\"male\", \"female\"]\n",
    "    file_emotion, file_speaker_id, file_gender, file_path = [], [], [], []\n",
    "    for gender in genders:\n",
    "        emotion_dirs = os.listdir(os.path.join(DATASET_DIR, gender))\n",
    "        if not irritation:\n",
    "            emotion_dirs = [emotion_dir for emotion_dir in emotion_dirs if emotion_dir != \"irritation\"]\n",
    "        for emotion_dir in emotion_dirs:\n",
    "            for file in os.listdir(os.path.join(DATASET_DIR, gender, emotion_dir)):\n",
    "                if file.endswith(\".wav\"):\n",
    "                    speaker_id = file[:5] if file[:4].lower() == \"b511\" else file[:4].upper()\n",
    "                    file_emotion.append(emotion_dir)\n",
    "                    file_speaker_id.append(speaker_id)\n",
    "                    file_gender.append(gender)\n",
    "                    file_path.append(os.path.join(DATASET_DIR, gender, emotion_dir, file))\n",
    "    emoiit_df = pd.DataFrame({'emotion': file_emotion, 'speaker_id': file_speaker_id, 'gender': file_gender, 'path': file_path}).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    return emoiit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(ser_df):\n",
    "    audio_block_list = []\n",
    "    emotion_list = []\n",
    "    for row in tqdm(ser_df.itertuples(), desc=f\"Preprocessing audio files dataset\", total=len(ser_df)):\n",
    "        data, _ = librosa.load(row.path, sr=SAMPLE_RATE)\n",
    "        if data.shape[0] < SAMPLE_RATE:\n",
    "            data = np.pad(data, (0, SAMPLE_RATE - data.shape[0]), 'constant')\n",
    "        frames = librosa.util.frame(data, frame_length=SAMPLE_RATE, hop_length=int(SAMPLE_RATE/100)).T\n",
    "        for frame in frames:\n",
    "            audio_block_list.append(frame)\n",
    "            emotion_list.append(row.emotion)\n",
    "    audio_block_list = np.array(audio_block_list)\n",
    "    emotion_list = np.array(emotion_list)\n",
    "    ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "    emotion_list = ohe.fit_transform(emotion_list[:, np.newaxis])\n",
    "    return audio_block_list, emotion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_df = create_dataframe_emoiit_gendered(irritation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing audio files dataset: 100%|██████████| 522/522 [00:02<00:00, 225.58it/s]\n",
      "c:\\Users\\bogda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_block_list, emotion_list = preprocess_dataset(ser_df)\n",
    "num_spectograms_without_irritation = len(audio_block_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spectrograms without irritation: 15054\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of spectrograms without irritation: {len(audio_block_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hapiness</td>\n",
       "      <td>B523</td>\n",
       "      <td>female</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\female\\h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>B301</td>\n",
       "      <td>female</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\female\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>B308</td>\n",
       "      <td>male</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\male\\ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>B326</td>\n",
       "      <td>male</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\male\\neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>B326</td>\n",
       "      <td>male</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\male\\dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>disgust</td>\n",
       "      <td>B313</td>\n",
       "      <td>male</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\male\\dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>fear</td>\n",
       "      <td>B323</td>\n",
       "      <td>male</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\male\\fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>anger</td>\n",
       "      <td>B523</td>\n",
       "      <td>female</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\female\\a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>hapiness</td>\n",
       "      <td>B523</td>\n",
       "      <td>female</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\female\\h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>fear</td>\n",
       "      <td>B319</td>\n",
       "      <td>male</td>\n",
       "      <td>Datasets/EMO-IIT_Separate_Speakers_v2\\male\\fea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion speaker_id  gender  \\\n",
       "0    hapiness       B523  female   \n",
       "1     neutral       B301  female   \n",
       "2       anger       B308    male   \n",
       "3     neutral       B326    male   \n",
       "4     disgust       B326    male   \n",
       "..        ...        ...     ...   \n",
       "517   disgust       B313    male   \n",
       "518      fear       B323    male   \n",
       "519     anger       B523  female   \n",
       "520  hapiness       B523  female   \n",
       "521      fear       B319    male   \n",
       "\n",
       "                                                  path  \n",
       "0    Datasets/EMO-IIT_Separate_Speakers_v2\\female\\h...  \n",
       "1    Datasets/EMO-IIT_Separate_Speakers_v2\\female\\n...  \n",
       "2    Datasets/EMO-IIT_Separate_Speakers_v2\\male\\ang...  \n",
       "3    Datasets/EMO-IIT_Separate_Speakers_v2\\male\\neu...  \n",
       "4    Datasets/EMO-IIT_Separate_Speakers_v2\\male\\dis...  \n",
       "..                                                 ...  \n",
       "517  Datasets/EMO-IIT_Separate_Speakers_v2\\male\\dis...  \n",
       "518  Datasets/EMO-IIT_Separate_Speakers_v2\\male\\fea...  \n",
       "519  Datasets/EMO-IIT_Separate_Speakers_v2\\female\\a...  \n",
       "520  Datasets/EMO-IIT_Separate_Speakers_v2\\female\\h...  \n",
       "521  Datasets/EMO-IIT_Separate_Speakers_v2\\male\\fea...  \n",
       "\n",
       "[522 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_id  gender\n",
       "B301        female    24\n",
       "B303        female    28\n",
       "B306        female    27\n",
       "B307        male      26\n",
       "B308        male      28\n",
       "B313        male      28\n",
       "B318        female    26\n",
       "B319        male      18\n",
       "B323        male      28\n",
       "B326        male      28\n",
       "B329        male      16\n",
       "B403        female    27\n",
       "B410        male      24\n",
       "B424        male      28\n",
       "B511a       female    21\n",
       "            male       7\n",
       "B512        female    28\n",
       "B518        female    56\n",
       "B523        female    54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_by_speaker_gender = ser_df.groupby(['speaker_id', 'gender']).size()\n",
    "sorted_counts = count_by_speaker_gender.sort_index()\n",
    "sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    291\n",
       "male      231\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_df[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger       76\n",
       "boredom     71\n",
       "disgust     63\n",
       "fear        80\n",
       "hapiness    79\n",
       "neutral     79\n",
       "sadness     74\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_df['emotion'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion   gender\n",
       "anger     female    43\n",
       "          male      33\n",
       "boredom   female    43\n",
       "          male      28\n",
       "disgust   female    35\n",
       "          male      28\n",
       "fear      female    43\n",
       "          male      37\n",
       "hapiness  female    42\n",
       "          male      37\n",
       "neutral   female    42\n",
       "          male      37\n",
       "sadness   female    43\n",
       "          male      31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_by_emotion_gender = ser_df.groupby(['emotion', 'gender']).size()\n",
    "sorted_counts = count_by_emotion_gender.sort_index()\n",
    "sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Person B301\n",
      "anger       4\n",
      "boredom     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B303\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B306\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     3\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B307\n",
      "anger       4\n",
      "boredom     3\n",
      "disgust     3\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B308\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B313\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B318\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    3\n",
      "neutral     3\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B319\n",
      "anger       4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     2\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B323\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B326\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B329\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B403\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     3\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B410\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B424\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B511a\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B512\n",
      "anger       4\n",
      "boredom     4\n",
      "disgust     4\n",
      "fear        4\n",
      "hapiness    4\n",
      "neutral     4\n",
      "sadness     4\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B518\n",
      "anger       8\n",
      "boredom     8\n",
      "disgust     8\n",
      "fear        8\n",
      "hapiness    8\n",
      "neutral     8\n",
      "sadness     8\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Person B523\n",
      "anger       8\n",
      "boredom     8\n",
      "disgust     6\n",
      "fear        8\n",
      "hapiness    8\n",
      "neutral     8\n",
      "sadness     8\n",
      "Name: emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "person_list = sorted(ser_df['speaker_id'].unique().tolist())\n",
    "for person in person_list:\n",
    "    print(f\"\\nPerson {person}\")\n",
    "    print(ser_df[ser_df['speaker_id'] == person]['emotion'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_df = create_dataframe_emoiit_gendered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing audio files dataset: 100%|██████████| 562/562 [00:00<00:00, 1162.24it/s]\n",
      "c:\\Users\\bogda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_block_list, emotion_list = preprocess_dataset(ser_df)\n",
    "num_spectograms_with_irritation = len(audio_block_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio blocks with irritation included: 33949\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of audio blocks with irritation included: {len(audio_block_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of audio blocks without irritation is 15054 and the number of audio blocks with irritation is 33949, so with the addition of irritation, the number of audio blocks increased with a percent of 125.51%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of audio blocks without irritation is {num_spectograms_without_irritation} and the number of audio blocks with irritation is {num_spectograms_with_irritation}, so with the addition of irritation, the number of audio blocks increased with a percent of {100*(num_spectograms_with_irritation - num_spectograms_without_irritation)/num_spectograms_without_irritation:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion     gender\n",
       "anger       female    43\n",
       "            male      33\n",
       "boredom     female    43\n",
       "            male      28\n",
       "disgust     female    35\n",
       "            male      28\n",
       "fear        female    43\n",
       "            male      37\n",
       "hapiness    female    42\n",
       "            male      37\n",
       "irritation  female    17\n",
       "            male      23\n",
       "neutral     female    42\n",
       "            male      37\n",
       "sadness     female    43\n",
       "            male      31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_by_emotion_gender = ser_df.groupby(['emotion', 'gender']).size()\n",
    "sorted_counts = count_by_emotion_gender.sort_index()\n",
    "sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
